{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotionRec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16cTynXoiUZUXlK9TwSgUCFchzO8gBXOG",
      "authorship_tag": "ABX9TyPznTACfckt9VAcD0zUKxlx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habiib1999/Speech-Emotion-Recognition/blob/main/emotionRecMain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uCKGmYYqKg7"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "import re\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import Audio\n",
        "# from entropy import spectral_entropy\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "import itertools"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REhck2ccqVCA"
      },
      "source": [
        "# CLASS : READER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-RmL2riqQ24"
      },
      "source": [
        "#READER CLASS\n",
        "class Reader:\n",
        "  def __init__(self, crema_path):\n",
        "    self.crema_path = crema_path\n",
        "\n",
        "\n",
        "  def readCrema(self):\n",
        "    emotion_df = []\n",
        "\n",
        "    for wav in os.listdir(crema_path):\n",
        "      info = wav.partition(\".wav\")[0].split(\"_\")\n",
        "      if info[2] == 'SAD':\n",
        "        emotion_df.append((\"sad\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'ANG':\n",
        "        emotion_df.append((\"angry\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'DIS':\n",
        "        emotion_df.append((\"disgust\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'FEA':\n",
        "        emotion_df.append((\"fear\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'HAP':\n",
        "        emotion_df.append((\"happy\", crema_path + \"/\" + wav))\n",
        "      elif info[2] == 'NEU':\n",
        "        emotion_df.append((\"neutral\", crema_path + \"/\" + wav))\n",
        "      else:\n",
        "        emotion_df.append((\"unknown\", crema_path + \"/\" + wav))\n",
        "\n",
        "\n",
        "    Crema_df = pd.DataFrame.from_dict(emotion_df)\n",
        "    Crema_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
        "\n",
        "    #print(Crema_df.head())\n",
        "    return Crema_df\n",
        "\n",
        " \n",
        "\n",
        "  def read(self):\n",
        "    crema_dataset = self.readCrema()\n",
        "    return crema_dataset\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-QNXEgVr0Iq",
        "outputId": "e737d327-a9a6-468d-9249-aac4d670661f"
      },
      "source": [
        "crema_path = \"/content/drive/MyDrive/emotionDataset/Crema\"\n",
        "reader = Reader(crema_path)\n",
        "crema_dataset = reader.read()\n",
        "#from sklearn.utils import shuffle\n",
        "#crema_dataset = shuffle(crema_dataset)\n",
        "print(crema_dataset.head(10))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Emotion                                               Path\n",
            "0     fear  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "1     fear  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "2      sad  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "3  disgust  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "4  disgust  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "5    angry  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "6      sad  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "7  disgust  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "8     fear  /content/drive/MyDrive/emotionDataset/Crema/10...\n",
            "9     fear  /content/drive/MyDrive/emotionDataset/Crema/10...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M33xepUItR0h"
      },
      "source": [
        "def energy(data, frame_length=2048, hop_length=512):\n",
        "    en = np.array([np.sum(np.power(np.abs(data[hop:hop+frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n",
        "    return en / frame_length\n",
        "def mel_spc(data, sr, frame_length=2048, hop_length=512, flatten: bool = False):\n",
        "    mel = librosa.feature.melspectrogram(y=data, sr=sr)\n",
        "    return np.squeeze(mel.T) if not flatten else np.ravel(mel.T)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLFh_zXztUEx"
      },
      "source": [
        "def extract_features(data, sr, frame_length=2048, hop_length=512):\n",
        "    result = np.array([])\n",
        "\n",
        "    return energy(data, frame_length, hop_length),mel_spc(data, sr, frame_length, hop_length)\n",
        "\n",
        "\n",
        "def get_features(path, duration=2.5, offset=0.6):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
        "    data, sample_rate = librosa.load(path, duration=duration, offset=offset)\n",
        "\n",
        "    energy_feature,mel_spec_feature = extract_features(data, sample_rate)\n",
        "\n",
        "    return np.array(energy_feature) , np.array(mel_spec_feature)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqsKXQeytW4q",
        "outputId": "9a7965ea-bc56-449c-dabf-e9894f151bca"
      },
      "source": [
        "path = np.array(crema_dataset[\"Path\"])[657]\n",
        "data, sampling_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
        "print(len(data))\n",
        "print(data)\n",
        "print(sampling_rate)\n",
        "enrg = energy(data)\n",
        "mel_spec = mel_spc(data, sampling_rate)\n",
        "print(\"Energy shape: \", enrg.shape)\n",
        "print(\"Energy: \", enrg)\n",
        "print(\"MelSpectrogram shape: \", mel_spec.shape)\n",
        "print(\"MelSpectrogram : \", mel_spec)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41215\n",
            "[-0.00774202 -0.00921047 -0.00838774 ...  0.          0.\n",
            "  0.        ]\n",
            "22050\n",
            "Energy shape:  (81,)\n",
            "Energy:  [1.25416682e-05 9.00268205e-05 1.85334604e-04 3.20473308e-04\n",
            " 4.43909288e-04 5.84825990e-04 6.93780254e-04 7.57424335e-04\n",
            " 7.28843384e-04 5.22820163e-04 3.26876121e-04 2.08084093e-04\n",
            " 3.37646983e-04 4.53232380e-04 6.37009856e-04 6.90810732e-04\n",
            " 6.26968686e-04 6.22040359e-04 5.71376935e-04 5.53829479e-04\n",
            " 5.40389272e-04 5.17104869e-04 4.33028355e-04 3.69260844e-04\n",
            " 3.49385751e-04 6.80433295e-04 9.92599176e-04 1.06770382e-03\n",
            " 1.07393204e-03 7.50555773e-04 3.96377407e-04 3.65105516e-04\n",
            " 3.75498668e-04 3.81877937e-04 4.22568090e-04 4.03064187e-04\n",
            " 3.02504777e-04 2.81216606e-04 3.60311329e-04 4.31530643e-04\n",
            " 5.63004171e-04 7.37200084e-04 9.54805641e-04 1.11985242e-03\n",
            " 1.10804976e-03 1.04999903e-03 7.55362853e-04 4.82189003e-04\n",
            " 3.56042641e-04 1.70072773e-04 1.18846765e-04 8.40425055e-05\n",
            " 5.14617059e-05 3.80887905e-05 3.09384013e-05 2.71017125e-05\n",
            " 2.12698069e-05 1.17438049e-05 1.07665437e-05 1.08715294e-05\n",
            " 1.23392583e-05 1.23855716e-05 1.46490065e-05 1.33187159e-05\n",
            " 1.21409939e-05 1.05156441e-05 8.16990178e-06 9.15207420e-06\n",
            " 1.02486401e-05 1.11011195e-05 9.76844694e-06 1.15008143e-05\n",
            " 1.33482454e-05 1.73499557e-05 1.92684947e-05 1.94702225e-05\n",
            " 2.03762938e-05 1.50434134e-05 1.19652250e-05 7.26609915e-06\n",
            " 1.04658591e-06]\n",
            "MelSpectrogram shape:  (81, 128)\n",
            "MelSpectrogram :  [[2.82664225e-02 1.04450226e-01 6.14331961e-02 ... 5.19210403e-07\n",
            "  5.07533969e-07 5.00214696e-07]\n",
            " [7.12602446e-03 4.81470935e-02 3.01526450e-02 ... 1.29802174e-07\n",
            "  1.26883037e-07 1.25053234e-07]\n",
            " [3.83137213e-03 1.00347865e-02 1.38565553e-02 ... 5.96826892e-17\n",
            "  4.24376775e-17 4.62865654e-17]\n",
            " ...\n",
            " [2.82532629e-03 2.53526196e-02 4.74306606e-02 ... 7.16526743e-17\n",
            "  6.94315554e-17 6.92266528e-17]\n",
            " [2.75239511e-03 5.80586717e-02 1.01982437e-01 ... 1.25222175e-16\n",
            "  1.17597568e-16 1.20690787e-16]\n",
            " [6.93903305e-03 4.20200638e-02 4.97190244e-02 ... 9.21484827e-17\n",
            "  1.21594888e-16 1.46754586e-16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhIIC10stbZJ",
        "outputId": "ff7df6aa-d900-434d-e18b-ee5d33325766"
      },
      "source": [
        "extracted_data_energy, extracted_data_mel_spec = [], []\n",
        "extracted_data_energy_labels, extracted_data_mel_spec_labels = [], []\n",
        "print(\"Feature processing...\")\n",
        "for path, emotion, ind in zip(crema_dataset.Path, crema_dataset.Emotion, range(crema_dataset.Path.shape[0])):\n",
        "    energy_feature,mel_spec_feature = get_features(path)\n",
        "    if ind % 100 == 0:\n",
        "        print(f\"{ind} samples has been processed...\")\n",
        "    extracted_data_energy.append(energy_feature)      \n",
        "    extracted_data_energy_labels.append(emotion)\n",
        "    extracted_data_mel_spec.append(mel_spec_feature)      \n",
        "    extracted_data_mel_spec_labels.append(emotion)\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature processing...\n",
            "0 samples has been processed...\n",
            "100 samples has been processed...\n",
            "200 samples has been processed...\n",
            "300 samples has been processed...\n",
            "400 samples has been processed...\n",
            "500 samples has been processed...\n",
            "600 samples has been processed...\n",
            "700 samples has been processed...\n",
            "800 samples has been processed...\n",
            "900 samples has been processed...\n",
            "1000 samples has been processed...\n",
            "1100 samples has been processed...\n",
            "1200 samples has been processed...\n",
            "1300 samples has been processed...\n",
            "1400 samples has been processed...\n",
            "1500 samples has been processed...\n",
            "1600 samples has been processed...\n",
            "1700 samples has been processed...\n",
            "1800 samples has been processed...\n",
            "1900 samples has been processed...\n",
            "2000 samples has been processed...\n",
            "2100 samples has been processed...\n",
            "2200 samples has been processed...\n",
            "2300 samples has been processed...\n",
            "2400 samples has been processed...\n",
            "2500 samples has been processed...\n",
            "2600 samples has been processed...\n",
            "2700 samples has been processed...\n",
            "2800 samples has been processed...\n",
            "2900 samples has been processed...\n",
            "3000 samples has been processed...\n",
            "3100 samples has been processed...\n",
            "3200 samples has been processed...\n",
            "3300 samples has been processed...\n",
            "3400 samples has been processed...\n",
            "3500 samples has been processed...\n",
            "3600 samples has been processed...\n",
            "3700 samples has been processed...\n",
            "3800 samples has been processed...\n",
            "3900 samples has been processed...\n",
            "4000 samples has been processed...\n",
            "4100 samples has been processed...\n",
            "4200 samples has been processed...\n",
            "4300 samples has been processed...\n",
            "4400 samples has been processed...\n",
            "4500 samples has been processed...\n",
            "4600 samples has been processed...\n",
            "4700 samples has been processed...\n",
            "4800 samples has been processed...\n",
            "4900 samples has been processed...\n",
            "5000 samples has been processed...\n",
            "5100 samples has been processed...\n",
            "5200 samples has been processed...\n",
            "5300 samples has been processed...\n",
            "5400 samples has been processed...\n",
            "5500 samples has been processed...\n",
            "5600 samples has been processed...\n",
            "5700 samples has been processed...\n",
            "5800 samples has been processed...\n",
            "5900 samples has been processed...\n",
            "6000 samples has been processed...\n",
            "6100 samples has been processed...\n",
            "6200 samples has been processed...\n",
            "6300 samples has been processed...\n",
            "6400 samples has been processed...\n",
            "6500 samples has been processed...\n",
            "6600 samples has been processed...\n",
            "6700 samples has been processed...\n",
            "6800 samples has been processed...\n",
            "6900 samples has been processed...\n",
            "7000 samples has been processed...\n",
            "7100 samples has been processed...\n",
            "7200 samples has been processed...\n",
            "7300 samples has been processed...\n",
            "7400 samples has been processed...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "k_qZsg9stfcU",
        "outputId": "0877cb50-7ab4-4b25-acb5-dc73d31ef3d2"
      },
      "source": [
        "features_path = \"/content/drive/MyDrive/emotionDataset/crema_energy_features.csv\"\n",
        "extracted_df = pd.DataFrame(extracted_data_energy)\n",
        "extracted_df[\"labels\"] = extracted_data_energy_labels\n",
        "extracted_df.to_csv(features_path, index=False)\n",
        "extracted_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000157</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.000587</td>\n",
              "      <td>0.000858</td>\n",
              "      <td>0.000934</td>\n",
              "      <td>0.000844</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.000161</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.012323</td>\n",
              "      <td>0.066642</td>\n",
              "      <td>0.094322</td>\n",
              "      <td>0.124989</td>\n",
              "      <td>0.130533</td>\n",
              "      <td>0.095000</td>\n",
              "      <td>0.077821</td>\n",
              "      <td>0.052947</td>\n",
              "      <td>0.041790</td>\n",
              "      <td>0.023789</td>\n",
              "      <td>0.012663</td>\n",
              "      <td>0.017132</td>\n",
              "      <td>0.018025</td>\n",
              "      <td>0.034618</td>\n",
              "      <td>0.043925</td>\n",
              "      <td>0.035394</td>\n",
              "      <td>0.032040</td>\n",
              "      <td>0.013879</td>\n",
              "      <td>0.005472</td>\n",
              "      <td>0.004253</td>\n",
              "      <td>0.003301</td>\n",
              "      <td>0.003832</td>\n",
              "      <td>0.004409</td>\n",
              "      <td>0.004036</td>\n",
              "      <td>0.004221</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>0.001963</td>\n",
              "      <td>0.001194</td>\n",
              "      <td>0.001412</td>\n",
              "      <td>0.003720</td>\n",
              "      <td>0.015239</td>\n",
              "      <td>0.028289</td>\n",
              "      <td>0.035175</td>\n",
              "      <td>0.046813</td>\n",
              "      <td>0.050180</td>\n",
              "      <td>0.051656</td>\n",
              "      <td>0.053262</td>\n",
              "      <td>0.042210</td>\n",
              "      <td>0.044249</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>6.883546e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.000555</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.000767</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.000516</td>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.000635</td>\n",
              "      <td>0.000630</td>\n",
              "      <td>0.000627</td>\n",
              "      <td>0.000474</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.000296</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>0.001068</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>0.000351</td>\n",
              "      <td>0.000158</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.000328</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>2.649021e-05</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>3.974998e-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000182</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.000521</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.000402</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>0.000892</td>\n",
              "      <td>0.001104</td>\n",
              "      <td>0.001055</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>4.238462e-05</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>1.127197e-04</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.000088</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>0.000117</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000075</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.000444</td>\n",
              "      <td>0.000713</td>\n",
              "      <td>0.000993</td>\n",
              "      <td>0.001350</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.001649</td>\n",
              "      <td>0.001925</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>0.002866</td>\n",
              "      <td>0.003592</td>\n",
              "      <td>0.003995</td>\n",
              "      <td>0.003897</td>\n",
              "      <td>0.003309</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.000828</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.000691</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.000680</td>\n",
              "      <td>0.000934</td>\n",
              "      <td>0.002013</td>\n",
              "      <td>2.552214e-03</td>\n",
              "      <td>0.003398</td>\n",
              "      <td>0.003889</td>\n",
              "      <td>0.003068</td>\n",
              "      <td>0.002526</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.000749</td>\n",
              "      <td>0.000508</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>3.569985e-04</td>\n",
              "      <td>0.000248</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 109 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...       106       107   labels\n",
              "0  0.000157  0.000105  0.000075  ...       NaN       NaN     fear\n",
              "1  0.012323  0.066642  0.094322  ...       NaN       NaN     fear\n",
              "2  0.000680  0.000572  0.000464  ...       NaN       NaN      sad\n",
              "3  0.000021  0.000026  0.000032  ...  0.000008  0.000002  disgust\n",
              "4  0.000025  0.000024  0.000033  ...  0.000007  0.000004  disgust\n",
              "\n",
              "[5 rows x 109 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "fZ5jHHcithc5",
        "outputId": "c1382c33-cdc7-410d-ec85-72117932e202"
      },
      "source": [
        "features_path = \"/content/drive/MyDrive/emotionDataset/crema_mel_spec_features.csv\"\n",
        "extracted_df = pd.DataFrame(extracted_data_mel_spec)\n",
        "extracted_df[\"labels\"] = extracted_data_mel_spec_labels\n",
        "extracted_df.to_csv(features_path, index=False)\n",
        "extracted_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py:305: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  values = np.array([convert(v) for v in values])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.3735934, 0.6247544, 1.9075246, 2.1719446, ...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.110143304, 0.01234068, 0.010340791, 0.1479...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.09649463, 0.17921183, 0.085100114, 0.18549...</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[0.17824107, 0.034192763, 0.040228058, 0.0265...</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.04045482, 0.003997328, 0.030719493, 0.0737...</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0   labels\n",
              "0  [[0.3735934, 0.6247544, 1.9075246, 2.1719446, ...     fear\n",
              "1  [[0.110143304, 0.01234068, 0.010340791, 0.1479...     fear\n",
              "2  [[0.09649463, 0.17921183, 0.085100114, 0.18549...      sad\n",
              "3  [[0.17824107, 0.034192763, 0.040228058, 0.0265...  disgust\n",
              "4  [[0.04045482, 0.003997328, 0.030719493, 0.0737...  disgust"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGpG03-Itkd5",
        "outputId": "34ad09a5-eba0-4cd7-a626-256f91164ca5"
      },
      "source": [
        "features_path = \"/content/drive/MyDrive/emotionDataset/crema_energy_features.csv\"\n",
        "energy_data = pd.read_csv(features_path)\n",
        "energy_data.head()\n",
        "print(energy_data)\n",
        "print(energy_data.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             0         1         2  ...       106       107   labels\n",
            "0     0.000157  0.000105  0.000075  ...       NaN       NaN     fear\n",
            "1     0.012323  0.066642  0.094322  ...       NaN       NaN     fear\n",
            "2     0.000680  0.000572  0.000464  ...       NaN       NaN      sad\n",
            "3     0.000021  0.000026  0.000032  ...  0.000008  0.000002  disgust\n",
            "4     0.000025  0.000024  0.000033  ...  0.000007  0.000004  disgust\n",
            "...        ...       ...       ...  ...       ...       ...      ...\n",
            "7437  0.000016  0.000021  0.000033  ...  0.000009  0.000004  disgust\n",
            "7438  0.000018  0.000019  0.000022  ...  0.000020  0.000006  neutral\n",
            "7439  0.000043  0.000055  0.000069  ...       NaN       NaN  disgust\n",
            "7440  0.023445  0.024009  0.013516  ...  0.000020  0.000007    angry\n",
            "7441  0.005099  0.014057  0.016144  ...  0.000022  0.000003    angry\n",
            "\n",
            "[7442 rows x 109 columns]\n",
            "(7442, 109)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXH0f94etmZ7",
        "outputId": "4f0c2087-2206-4abd-c57f-f162114e6305"
      },
      "source": [
        "features_path = \"/content/drive/MyDrive/emotionDataset/crema_mel_spec_features.csv\"\n",
        "mel_spec_data = pd.read_csv(features_path)\n",
        "mel_spec_data.head()\n",
        "print(mel_spec_data)\n",
        "print(len(mel_spec_data.loc[0][0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                      0   labels\n",
            "0     [[3.73593390e-01 6.24754429e-01 1.90752459e+00...     fear\n",
            "1     [[1.10143304e-01 1.23406798e-02 1.03407912e-02...     fear\n",
            "2     [[9.6494630e-02 1.7921183e-01 8.5100114e-02 .....      sad\n",
            "3     [[1.7824107e-01 3.4192763e-02 4.0228058e-02 .....  disgust\n",
            "4     [[4.04548198e-02 3.99732823e-03 3.07194926e-02...  disgust\n",
            "...                                                 ...      ...\n",
            "7437  [[8.1536090e-03 4.9170428e-03 2.2856034e-03 .....  disgust\n",
            "7438  [[8.93165916e-03 2.35754643e-02 2.67566908e-02...  neutral\n",
            "7439  [[2.57985473e-01 1.21228591e-01 7.34253973e-03...  disgust\n",
            "7440  [[6.95406944e-02 2.77917944e-02 7.31072295e-03...    angry\n",
            "7441  [[6.52315887e-03 1.59181282e-02 1.01051880e-02...    angry\n",
            "\n",
            "[7442 rows x 2 columns]\n",
            "599\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}